{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of vc-part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f99b194f15d74f20be1f436b29bd77a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9bab3c378620492e8297eddb1a93a334",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c8a4b37e24c4cbc89bc8e5adbfceaa4",
              "IPY_MODEL_d2182facc102431b87cbefb95834039a"
            ]
          }
        },
        "9bab3c378620492e8297eddb1a93a334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c8a4b37e24c4cbc89bc8e5adbfceaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d793f3369dee4c21aac87d7f9683284f",
            "_dom_classes": [],
            "description": "Transcribing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9a117f7f6754db8b4e394e95c97879b"
          }
        },
        "d2182facc102431b87cbefb95834039a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e507ea01bc7e4827989916be9dfbc160",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:04&lt;00:00,  4.39s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff91d418948245fd8e54d036897adca9"
          }
        },
        "d793f3369dee4c21aac87d7f9683284f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9a117f7f6754db8b4e394e95c97879b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e507ea01bc7e4827989916be9dfbc160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff91d418948245fd8e54d036897adca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZJLUH5sKYpH"
      },
      "source": [
        "##Demo\n",
        "Demo with telegram bot that converts your voice into Beyonce's by default but you can the voice that it converts to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGc7KVtGExct"
      },
      "source": [
        "!git clone https://github.com/EdvardOlsen/VoiceConversion.git\n",
        "!chmod 777 VoiceConversion/setup.sh\n",
        "!./VoiceConversion/setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3ltkhhbbmM"
      },
      "source": [
        "import nemo\n",
        "# NeMo's ASR collection - this collections contains complete ASR models and\n",
        "# building blocks (modules) for ASR\n",
        "import nemo.collections.asr as nemo_asr\n",
        "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\n",
        "def recognise_quartznet(audio_file):\n",
        "  return quartznet.transcribe(paths2audio_files=[audio_file])[0]\n",
        "\n",
        "recognise_quartznet('../audio.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp-F7wyIgsU6",
        "outputId": "af4add1e-be9a-4680-d93e-8ec8000a1c38"
      },
      "source": [
        "cd Real-Time-Voice-Cloning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Real-Time-Voice-Cloning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73SM1dWLhJPT"
      },
      "source": [
        "from IPython.display import Audio\n",
        "from IPython.utils import io\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import librosa\n",
        "encoder_weights = Path(\"encoder/saved_models/pretrained.pt\")\n",
        "vocoder_weights = Path(\"vocoder/saved_models/pretrained/pretrained.pt\")\n",
        "syn_dir = Path(\"synthesizer/saved_models/logs-pretrained/taco_pretrained\")\n",
        "encoder.load_model(encoder_weights)\n",
        "synthesizer = Synthesizer(syn_dir)\n",
        "vocoder.load_model(vocoder_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9eHMPfBhKqS"
      },
      "source": [
        "import soundfile as sf\n",
        "text = \"time to come to twenty twentyone with a better vocoder\"\n",
        "in_fpath = Path(\"../audio.wav\")\n",
        "original_wav, sampling_rate = librosa.load(in_fpath)\n",
        "preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
        "embed = encoder.embed_utterance(preprocessed_wav)\n",
        "\n",
        "def synthesis(text, embed):\n",
        "  with io.capture_output() as captured:\n",
        "    specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  sf.write('generated.wav', generated_wav, synthesizer.sample_rate)\n",
        "  \n",
        "\n",
        "synthesis(text, embed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG82UoRkiLlh"
      },
      "source": [
        "import IPython\n",
        "IPython.display.Audio('generated.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXjyQ0QLnhKi"
      },
      "source": [
        "data, sr = librosa.load('tmp.wav', 44100)\n",
        "tmp10sec = 44100*5\n",
        "x = 1100000"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_zYu8hZnqUu"
      },
      "source": [
        "info = data[x-tmp10sec:x+8000]\n",
        "info = librosa.resample(info, 44100, 16000)\n",
        "sf.write('trump.wav', info, 16000)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "f99b194f15d74f20be1f436b29bd77a4",
            "9bab3c378620492e8297eddb1a93a334",
            "9c8a4b37e24c4cbc89bc8e5adbfceaa4",
            "d2182facc102431b87cbefb95834039a",
            "d793f3369dee4c21aac87d7f9683284f",
            "e9a117f7f6754db8b4e394e95c97879b",
            "e507ea01bc7e4827989916be9dfbc160",
            "ff91d418948245fd8e54d036897adca9"
          ]
        },
        "id": "GNOgDiI8lFKI",
        "outputId": "f15c7b51-5f61-4f93-b350-86a68287b226"
      },
      "source": [
        "def voice_conversion(source_file, target_file):\n",
        "  text = recognise_quartznet(source_file)\n",
        "  original_wav, sampling_rate = librosa.load(target_file)\n",
        "  preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
        "  embed = encoder.embed_utterance(preprocessed_wav)\n",
        "  result = synthesis(text, embed)\n",
        "  return result\n",
        "\n",
        "voice_conversion('beyonce.wav', 'trump.wav')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f99b194f15d74f20be1f436b29bd77a4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Transcribing', max=1.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{| â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 66500/67200 | Batch Size: 7 | Gen Rate: 8.1kHz | }"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrYTNORK9I_l"
      },
      "source": [
        "data, sr = librosa.load('../audio.wav', 44100)\n",
        "data = librosa.resample(data, 44100, 16000)\n",
        "data = data[:16000*5]\n",
        "sf.write('beyonce.wav', data, 16000)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HowaCTINmAF4"
      },
      "source": [
        "IPython.display.Audio('beyonce.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkwdCtsImV9d"
      },
      "source": [
        "IPython.display.Audio('generated.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyVMWG3mCUhB",
        "outputId": "74d172f9-34e3-4bb1-b1b9-a9c20868412a"
      },
      "source": [
        "cd /content/Real-Time-Voice-Cloning/"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Real-Time-Voice-Cloning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18jS_cWYAmfH"
      },
      "source": [
        "token=''\n",
        "import telebot\n",
        "from urllib.request import urlretrieve\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "i = 0\n",
        "\n",
        "\n",
        "def convert_to_wav(filename):\n",
        "  data, sr = librosa.load(filename)\n",
        "  sf.write('tmp.wav', data, sr)\n",
        "  return 'tmp.wav'\n",
        "\n",
        "bot = telebot.TeleBot(token)\n",
        "@bot.message_handler(content_types=[\"audio\", \"document\", \"voice\"])\n",
        "def handle(message, i=10): \n",
        "    try:\n",
        "      file_info = bot.get_file(message.voice.file_id)\n",
        "      downloaded_file = bot.download_file(file_info.file_path)\n",
        "      with open('new_file.ogg', 'wb') as new_file:\n",
        "        new_file.write(downloaded_file)\n",
        "      new_name = convert_to_wav('new_file.ogg')\n",
        "      print('saved at new_file.ogg')\n",
        "      voice_conversion('tmp.wav', 'beyonce.wav')\n",
        "      bot.send_audio(chat_id=message.chat.id, audio=open('generated.wav', 'rb'))\n",
        "\n",
        "    except:\n",
        "      bot.send_message(chat_id=message.chat.id, text='error')"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bBP_ANrCBIM"
      },
      "source": [
        "bot.polling()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVwL1QpTCCOp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}